{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a784f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "FileContent1 = '''\n",
    "India, officially the Republic of India (ISO: Bhārat Gaṇarājya),[21] is a country in South Asia. It is the seventh-largest country by area; the most populous country as of June 2023;[22][23] and from the time of its independence in 1947, the world's most populous democracy.[24][25][26] Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[j] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia.\n",
    "\n",
    "Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[27][28][29] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[30] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[31] By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest.[32][33] Its evidence today is found in the hymns of the Rigveda. Preserved by an oral tradition that was resolutely vigilant, the Rigveda records the dawning of Hinduism in India.[34] The Dravidian languages of India were supplanted in the northern and western regions.[35] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[36] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[37] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.[38] Their collective era was suffused with wide-ranging creativity,[39] but also marked by the declining status of women,[40] and the incorporation of untouchability into an organised system of belief.[k][41] In South India, the Middle kingdoms exported Dravidian-languages scripts and religious cultures to the kingdoms of Southeast Asia.[42]\n",
    "\n",
    "In the early medieval era, Christianity, Islam, Judaism, and Zoroastrianism became established on India's southern and western coasts.[43] Muslim armies from Central Asia intermittently overran India's northern plains,[44] eventually founding the Delhi Sultanate, and drawing northern India into the cosmopolitan networks of medieval Islam.[45] In the 15th century, the Vijayanagara Empire created a long-lasting composite Hindu culture in south India.[46] In the Punjab, Sikhism emerged, rejecting institutionalised religion.[47] The Mughal Empire, in 1526, ushered in two centuries of relative peace,[48] leaving a legacy of luminous architecture.[l][49] Gradually expanding rule of the British East India Company followed, turning India into a colonial economy, but also consolidating its sovereignty.[50] British Crown rule began in 1858. The rights promised to Indians were granted slowly,[51][52] but technological changes were introduced, and modern ideas of education and the public life took root.[53] A pioneering and influential nationalist movement emerged, which was noted for nonviolent resistance and became the major factor in ending British rule.[54][55] In 1947 the British Indian Empire was partitioned into two independent dominions,[56][57][58][59] a Hindu-majority Dominion of India and a Muslim-majority Dominion of Pakistan, amid large-scale loss of life and an unprecedented migration.[60]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81af897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (4.36.0.dev0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (4.65.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (4.21.12)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[sentencepiece]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers[sentencepiece]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers[sentencepiece]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers[sentencepiece]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashmit_sinha\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers[sentencepiece]) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b158d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"C:\\Users\\ashmit_sinha\\readme.txt\", \"r\")\n",
    "FileContent = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "837a4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FileContent = FileContent1.strip().replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "941e68bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\\n\\nThe mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.[7][8]\\n\\nML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field\\'s methods.\\n\\n\\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[9][10] The synonym self-teaching computers was also used in this time period.[11][12]\\n\\nBy the early 1960s an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to re-evaluate incorrect decisions.[13] A representative book on research into machine learning during the 1960s was Nilsson\\'s book on Learning Machines, dealing mostly with machine learning for pattern classification.[14] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[15] In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[16]\\n\\nTom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\"[17] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing\\'s proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".[18]\\n\\nModern-day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.[19]\\n\\n\\nAs a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics.[21] Probabilistic reasoning was also employed, especially in automated medical diagnosis.[22]:â€Š488â€Š\\n\\nHowever, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.[22]:â€Š488â€Š By 1980, expert systems had come to dominate AI, and statistics was out of favor.[23] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming, but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.[22]:â€Š708â€“710,â€Š755â€Š Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines including Hopfield, Rumelhart, and Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.[22]:â€Š25â€Š\\n\\nMachine learning (ML), reorganized and recognized as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.[23]\\n\\n\\nMachine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"unsupervised learning\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.\\n\\nMachine learning also has intimate ties to optimization: many learning problems are formulated as minimization of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the pre-assigned labels of a set of examples).[24]\\n\\n\\nThe difference between optimization and machine learning arises from the goal of generalization: while optimization algorithms can minimize the loss on a training set, machine learning is concerned with minimizing the loss on unseen samples. Characterizing the generalization of various learning algorithms is an active topic of current research, especially for deep learning algorithms.\\n\\n\\nMachine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalizable predictive patterns.[25] According to Michael I. Jordan, the ideas of machine learning, from methodological principles to theoretical tools, have had a long pre-history in statistics.[26] He also suggested the term data science as a placeholder to call the overall field.[26]\\n\\nConventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.[27]\\n\\nLeo Breiman distinguished two statistical modeling paradigms: data model and algorithmic model,[28] wherein \"algorithmic model\" means more or less the machine learning algorithms like Random Forest.\\n\\nSome statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.[29]\\n\\n\\nAnalytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyze the weight space of deep neural networks.[30] Statistical physics is thus finding applications in the area of medical diagnostics.[31]\\n\\nA core objective of a learner is to generalize from its experience.[6][32] Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\\n\\nThe computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the Probably Approximately Correct Learning (PAC) model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The biasâ€“variance decomposition is one way to quantify generalization error.\\n\\nFor the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.[33]\\n\\nIn addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceac032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10953"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FileContent) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80df21e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b16e4142854d1fb6c6f3de1dc156d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashmit_sinha\\AppData\\Local\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashmit_sinha\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9245bc03b7554a4cb6327da99ccd5c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f373cf65708a4026b17e8e07ee0fe95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848dd368e3af4bdf855feb3836c90a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf4effa360a4a2e8d465f9368c844d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "checkpoint = \"sshleifer/distilbart-cnn-12-6\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ddf47a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ashmit_sinha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "sentences = nltk.tokenize.sent_tokenize(FileContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c6abc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.tokenize(sentence)) for sentence in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c0639ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 0\n",
    "chunk = \"\"\n",
    "chunks = []\n",
    "count = -1\n",
    "\n",
    "for sentence in sentences:\n",
    "    count += 1\n",
    "    combined_length = len(tokenizer.tokenize(sentence)) + length\n",
    "\n",
    "    if combined_length <= 500:\n",
    "        chunk += sentence + \" \"\n",
    "        length = combined_length\n",
    "\n",
    "        if count == len(sentences) - 1:\n",
    "            chunks.append(chunk.strip())\n",
    "\n",
    "    else:\n",
    "        chunks.append(chunk.strip())\n",
    "\n",
    "        length = len(tokenizer.tokenize(sentence))\n",
    "        chunk = sentence + \" \"\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45c8bbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[428, 468, 497, 482, 260]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(tokenizer.tokenize(c)) for c in chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08b185f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[430, 470, 499, 484, 262]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(tokenizer(c).input_ids) for c in chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc8c19c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(tokenizer(c).input_ids) for c in chunks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6e4883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2121 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2121"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(FileContent).input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a044f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [tokenizer(chunk, return_tensors=\"pt\") for chunk in chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3cd7254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions. Recently, generative artificial neural networks have been able to surpass many previous approaches in performance. ML is known in its application across business problems under the name predictive analytics. The term machine learning was coined in 1959 by an IBM employee and pioneer in the field of computer gaming and artificial intelligence.\n",
      " Machine learning grew out of the quest for artificial intelligence (AI) Modern-day machine learning has two objectives, one is to classify data based on models which have been developed, the other is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning to train it to classify cancerous moles.\n",
      " Machine learning is reorganized and recognized as its own field in the 1990s. The field shifted focus away from symbolic approaches inherited from AI, and toward methods borrowed from statistics, fuzzy logic, and probability theory. Machine learning and data mining often employ the same methods and overlap significantly. Data mining uses many machine learning methods but with different goals.\n",
      " The difference between optimization and machine learning arises from the goal of generalization. Characterizing the generalization of various learning algorithms is an active topic of current research. Statistics draws inferences from a sample, while machine learning finds generalizable predictive patterns. Some statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.\n",
      " Computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the Probably Approximately Correct Learning (PAC) model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms.\n"
     ]
    }
   ],
   "source": [
    "for input in inputs:\n",
    "  output = model.generate(**input)\n",
    "  print(tokenizer.decode(*output, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71a113c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1022"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_len_single_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea60fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
